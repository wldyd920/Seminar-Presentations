Abstract

이 백서는 미분 가능한 방식으로 작업을 공식화하여 아키텍처 검색의 확장성 문제를 해결합니다. 이산적이고 미분할 수 없는 검색 공간에 대해 진화 또는 강화 학습을 적용하는 기존 접근 방식과 달리, 우리의 방법은 아키텍처 표현의 지속적인 완화를 기반으로 하므로 경사하강법을 사용하여 아키텍처를 효율적으로 검색할 수 있습니다. CIFAR-10, ImageNet, Penn Treebank 및 WikiText-2에 대한 광범위한 실험은 우리 알고리즘이 이미지 분류를 위한 고성능 컨벌루션 아키텍처와 언어 모델링을 위한 순환 아키텍처를 발견하는 데 탁월함을 보여주면서도 상태보다 훨씬 더 빠릅니다. -예술 미분할 수 없는 기술. 우리의 구현은 효율적인 아키텍처 검색 알고리즘에 대한 추가 연구를 용이하게 하기 위해 공개적으로 제공되었습니다.


Introduction

최첨단 신경망 아키텍처를 발견하려면 인간 전문가의 상당한 노력이 필요합니다. 최근에는 아키텍처 설계의 수동 프로세스를 자동화하는 알고리즘 솔루션 개발에 대한 관심이 증가하고 있습니다. 자동 검색 아키텍처는 이미지 분류(Zoph & Le, 2017; Zoph et al., 2018; Liu et al., 2018b;a; Real et al., 2018) 및 객체 감지(Zoph & Le, 2017)와 같은 작업에서 매우 경쟁력 있는 성능을 달성했습니다. et al., 2018).

현존하는 최고의 아키텍처 검색 알고리즘은 놀라운 성능에도 불구하고 계산적으로 까다롭습니다. 예를 들어, CIFAR-10 및 ImageNet을 위한 최첨단 아키텍처를 얻으려면 2000 GPU RL(강화 학습)(Zoph et al., 2018) 또는 3150 GPU 진화(Real et al., 2018)가 필요했습니다. ). 검색 공간의 특정 구조(Liu et al., 2018b;a), 각 개별 아키텍처에 대한 가중치 또는 성능 예측(Brock et al., 2018; Baker et al. , 2018) 및 여러 아키텍처에 걸친 가중치 공유/상속(Elsken et al., 2017; Pham et al., 2018b; Cai et al., 2018; Bender et al., 2018)이 있지만 확장성의 근본적인 문제는 여전히 남아 있습니다. 지배적인 접근 방식에 대한 비효율의 고유한 원인, 예: RL, evolution, MCTS(Negrinho & Gordon, 2017), SMBO(Liu et al., 2018a) 또는 베이지안 최적화(Kandasamy et al., 2018)를 기반으로 아키텍처 검색이 블랙박스로 취급된다는 사실입니다. 이산 도메인에 대한 최적화 문제로 인해 많은 수의 아키텍처 평가가 필요합니다.

이 작업에서는 다른 각도에서 문제에 접근하고 DARTS(Differentiable ARchiTecture Search)라는 효율적인 아키텍처 검색 방법을 제안합니다. 개별 후보 아키텍처 집합을 검색하는 대신 검색 공간을 연속적으로 완화하여 아키텍처가 경사 하강법에 의한 유효성 검사 집합 성능과 관련하여 최적화될 수 있도록 합니다. 비효율적인 블랙박스 검색과 대조되는 그래디언트 기반 최적화의 데이터 효율성을 통해 DARTS는 훨씬 적은 수의 계산 리소스를 사용하여 최신 기술로 경쟁력 있는 성능을 달성할 수 있습니다. 또한 최근의 또 다른 효율적인 아키텍처 검색 방법인 ENAS보다 성능이 뛰어납니다(Pham et al., 2018b). 특히 DARTS는 컨트롤러를 포함하지 않기 때문에 기존의 많은 접근 방식보다 간단합니다(Zoph & Le, 2017; Baker et al., 2017; Zoph et al., 2018; Pham et al., 2018b; Zhong et al., 2018). , 하이퍼네트워크(Brock et al., 2018) 또는 성능 예측자(Liu et al., 2018a)가 포함되지만 컨볼루션 아키텍처와 순환 아키텍처를 모두 처리할 수 있을 만큼 충분히 일반적입니다.

연속 도메인 내에서 아키텍처를 검색한다는 아이디어는 새로운 것이 아니지만(Saxena & Verbeek, 2016; Ahmed & Torresani, 2017; Veniat & Denoyer, 2017; Shin et al., 2018) 몇 가지 주요 차이점이 있습니다. 이전 작업이 필터 모양 또는 컨볼루션 네트워크의 분기 패턴과 같은 아키텍처의 특정 측면을 미세 조정하려고 하는 반면 DARTS는 풍부한 검색 공간 내에서 복잡한 그래프 토폴로지를 사용하여 고성능 아키텍처 빌딩 블록을 학습할 수 있습니다. 또한 DARTS는 특정 아키텍처 제품군에 국한되지 않으며 컨볼루션 및 순환 네트워크 모두에 적용할 수 있습니다.

우리의 실험(섹션 3)에서 우리는 DARTS가 3.3M 매개변수를 사용하는 이미지 분류를 위해 CIFAR-10에서 2.76 ± 0.09% 테스트 오류를 ​​달성하는 컨볼루션 셀을 설계할 수 있음을 보여줍니다. 100배 더 많은 계산 리소스를 사용하여 얻은 정규화 진화(Real et al., 2018)에 의한 예술 결과입니다. 동일한 컨볼루션 셀도 ImageNet(모바일 설정)으로 전송할 때 26.7%의 상위 1 오류를 달성하며, 이는 최고의 RL 방법과 유사합니다(Zoph et al., 2018). 언어 모델링 작업에서 DARTS는 광범위하게 조정된 LSTM(Melis et al., 2018)과 NAS(Zoph & Le, 2017) 및 ENAS(Pham et al., 2018b) 를 뛰어넘는 성능을 보였습니다.


Contribution

우리는 이중 수준 최적화를 기반으로 하는 미분 가능한 네트워크 아키텍처 검색을 위한 새로운 알고리즘을 소개합니다. 이는 컨볼루션 아키텍처와 순환 아키텍처 모두에 적용 가능합니다.

이미지 분류 및 언어 모델링 작업에 대한 광범위한 실험을 통해 그라디언트 기반 아키텍처 검색이 CIFAR-10에서 매우 경쟁력 있는 결과를 달성하고 PTB에서 최신 기술을 능가한다는 것을 보여줍니다. 이것은 지금까지 최고의 아키텍처 검색 방법이 미분할 수 없는 검색 기술을 사용했다는 점을 고려하면 매우 흥미로운 결과입니다. RL(Zoph et al., 2018) 또는 진화(Real et al., 2018; Liu et al., 2018b)를 기반으로 합니다.

우리는 미분할 수 없는 검색 기술과 대조적으로 그래디언트 기반 최적화를 사용하여 놀라운 효율성 향상(아키텍처 발견 비용을 GPU로 몇 일 감소)을 달성했습니다.

CIFAR-10 및 PTB에서 DARTS가 학습한 아키텍처가 각각 ImageNet 및 WikiText-2로 전송될 수 있음을 보여줍니다.


Differentiable ARCHITECTURE SEARCH

섹션에서 검색 공간을 일반적인 형태로 설명합니다. 2.1에서 아키텍처(또는 그 안의 셀)에 대한 계산 절차는 방향성 비순환 그래프로 표시됩니다. 그런 다음 아키텍처와 가중치의 공동 최적화를 위한 미분 가능한 학습 목표로 이어지는 검색 공간에 대한 간단한 연속 완화 계획을 도입합니다(2.2절). 마지막으로 알고리즘을 계산적으로 실현 가능하고 효율적으로 만들기 위한 근사화 기법을 제안합니다(2.3절).

Search Space

Zoph et al. (2018); Real et al. (2018); Liu et al. (2018a;b) 에 따라, 우리는 최종 아키텍처의 빌딩 블록으로 계산 셀을 검색합니다. 학습된 셀은 누적되어 컨볼루션 네트워크를 형성하거나 재귀적으로 연결되어 순환 네트워크를 형성할 수 있습니다.

셀은 N 노드의 순서화된 시퀀스로 구성된 방향성 비순환 그래프입니다. 각 노드 x(i)는 잠재 표현(예: 컨볼루션 네트워크의 기능 맵)이고 각 방향 에지(i, j)는 x(i)를 변환하는 일부 작업 o(i,j)와 연관됩니다. 셀에 두 개의 입력 노드와 단일 출력 노드가 있다고 가정합니다. 컨볼루션 셀의 경우 입력 노드는 이전 두 계층의 셀 출력으로 정의됩니다(Zoph et al., 2018). 순환 셀의 경우 현재 단계의 입력과 이전 단계에서 가져온 상태로 정의됩니다. 셀의 출력은 모든 중간 노드에 축소 연산(예: 연결)을 적용하여 얻습니다. 각 중간 노드는 모든 선행 작업을 기반으로 계산됩니다.
(1)
그림1
두 노드 간의 연결 부족을 나타내기 위해 특별한 0 작업도 포함됩니다. 따라서 세포를 학습하는 작업은 가장자리에서 작업을 학습하는 것으로 축소됩니다.


지속적인 휴식과 최적화

O를 후보 연산 세트(예: 컨볼루션, 최대 풀링, 0)라고 하자. 여기서 각 연산은 x(i) 에 적용할 일부 기능 o(·)를 나타냅니다. 검색 공간을 연속적으로 만들기 위해 가능한 모든 작업에 대해 특정 작업의 범주형 선택을 소프트맥스로 완화합니다.
(2)

여기서 노드(i, j) 쌍에 대한 가중치 혼합 연산은 |O| 차원의 벡터 α(i,j)로 매개변수화됩니다. 아키텍처 탐색 작업은 그림 1과 같이 일련의 연속 변수 α = α(i,j)를 학습하는 것으로 축소됩니다. 탐색이 끝나면 각 혼합 연산을 대체하여 이산 아키텍처를 얻을 수 있습니다. (i,j) 가장 가능성 있는 연산, 즉 o(i,j) = argmax o∈O α(i,j)o . 다음에서 α를 (인코딩) 아키텍처라고 합니다.

이완 후, 우리의 목표는 모든 혼합 연산(예: 컨볼루션 필터의 가중치) 내에서 아키텍처 α와 가중치 w를 공동으로 학습하는 것입니다. 검증세트 성능이 보상 또는 적합성으로 취급되는 RL과 evolution과 유사하게 아키텍처 검색을 하지만 DARTS는 validation loss를 최적화하는 것을 목표로 하고, 경사 하강법을 사용합니다.

Ltrain과 Lval로 각각 훈련과 검증 손실을 나타냅니다. 두 손실 모두 아키텍처 α뿐만 아니라 네트워크의 가중치 w에 의해 결정됩니다. 아키텍처 검색의 목표는 검증 손실 Lval(w∗, α∗)을 최소화하는 α*를 찾는 것입니다. 여기서 아키텍처와 관련된 가중치 w*는 학습 손실 w* = argminw Ltrain(w, α∗)을 최소화하여 얻습니다. ).

이것은 α를 상위 수준 변수로, w를 하위 수준 변수로 사용하는 이중 수준 최적화 문제(Anandalingam & Friesz, 1992; Colson et al., 2007)를 의미합니다.
(삼)
(4)
중첩 공식은 기울기 기반 하이퍼파라미터 최적화에서도 발생합니다(Maclaurin et al., 2015; Pedregosa, 2016; Franceschi et al., 2018). 이는 아키텍처 α가 하이퍼파라미터의 특수 유형으로 볼 수 있다는 의미에서 관련이 있습니다. , 비록 그 차원이 학습률과 같은 스칼라 값 하이퍼파라미터보다 훨씬 높지만 최적화하기가 더 어렵습니다.
알고리즘1


2.3 대략적인 아키텍처 기울기

아키텍처 그라디언트를 정확히 평가하는 것은 값비싼 내부 최적화로 인해 금지될 수 있습니다. 따라서 우리는 다음과 같은 간단한 근사 계획을 제안합니다.
(5)
(6)
여기서 w는 알고리즘에 의해 유지되는 현재 가중치를 나타내고 ξ는 내부 최적화 단계에 대한 학습률입니다. 아이디어는 수렴할 때까지 훈련하여 내부 최적화(방정식 4)를 완전히 해결하지 않고 단일 훈련 단계만 사용하여 w를 조정하여 w*(α)를 근사화하는 것입니다. 관련 기술은 모델 전송(Finn et al., 2017), 그래디언트 기반 하이퍼파라미터 튜닝(Luketina et al., 2016) 및 풀린 생성적 적대 네트워크(Metz et al., 2017)를 위한 메타 학습에 사용되었습니다. 방정식 6은 w가 이미 내부 최적화에 대한 로컬 최적이고 따라서 ∇wLtrain(w, α) = 0인 경우 ∇αLval(w, α)로 감소합니다.

반복 절차는 Alg. 1. 우리는 현재 최적화 알고리즘에 대한 수렴 보장을 알지 못하지만 실제로는 ξ 의 적절한 선택으로 고정점에 도달할 수 있습니다. 또한 가중치 최적화를 위해 모멘텀이 활성화되면 방정식 6의 1단계 풀린 학습 목표가 그에 따라 수정되고 모든 분석이 여전히 적용됩니다. 대략적인 아키텍처 기울기(방정식 6)에 연쇄 규칙을 적용하면
(7)
여기서 w' = w−ξ∇wLtrain(w, α)은 1단계 전진 모델에 대한 가중치를 나타냅니다. 위의 표현식은 두 번째 항에 값비싼 행렬-벡터 곱을 포함합니다. 다행히도 유한 차분 근사(finite difference approximation)를 사용하여 복잡성을 상당히 줄일 수 있습니다. 작은 스칼라2라고 하고 w ± = w ± ∇w0Lval(w0, α). 그 다음에:
(8)
유한 차이를 평가하려면 가중치에 대해 2개의 전진 패스와 α에 대해 2개의 역방향 패스만 필요하며 복잡성은 O(|α||w|)에서 O(|α| + |w|)로 감소합니다. First-order Approximation :
ξ = 0이면 방정식 7의 2차 도함수가 사라집니다. 이 경우 아키텍처 기울기는 ∇αLval(w, α)로 주어지며, 이는 현재 w가 w*(α)와 같다고 가정하여 검증 손실을 최적화하는 단순 휴리스틱에 해당합니다. 이는 표 1 및 표 2의 실험 결과에 따라 속도 향상을 가져오지만 경험적으로 더 나쁜 성능을 나타냅니다. 다음에서 ξ = 0의 경우를 1차 근사값으로 참조하고 다음과 같은 기울기 공식을 참조합니다. ξ > 0은 2차 근사치입니다.

2.4 개별 아키텍처 도출

개별 아키텍처에서 각 노드를 형성하기 위해 우리는 모든 이전 노드에서 수집된 0이 아닌 모든 후보 작업 중에서 상위 k개의 가장 강력한 작업(개별 노드의)을 유지합니다. 연산의 강도는 exp(α(i,j) o) P o0∈O exp(α(i,j) o0)로 정의됩니다. 파생된 아키텍처를 기존 작업과 비교할 수 있도록 하기 위해 컨볼루션 셀에 대해 k = 2를 사용하고(Zoph et al., 2018; Liu et al., 2018a; Real et al., 2018) 순환 셀에 대해 k = 1을 사용합니다. (Pham et al., 2018b).
그림 2

위의 두 가지 이유로 Zero 작업은 제외됩니다. 첫째, 기존 모델과의 공정한 비교를 위해 노드당 정확히 k개의 0이 아닌 들어오는 에지가 필요합니다. 둘째, 제로 연산의 로짓을 증가시키면 결과 노드 표현의 규모에만 영향을 미치고 배치 정규화의 존재로 인해 최종 분류 결과에 영향을 미치지 않기 때문에 제로 연산의 강도가 과소 결정됩니다(Ioffe & Szegedy, 2015). .


3 실험 및 결과

CIFAR-10 및 PTB에 대한 우리의 실험은 아키텍처 검색(섹션 3.1)과 아키텍처 평가(섹션 3.2)의 두 단계로 구성됩니다. 첫 번째 단계에서는 DARTS를 사용하여 셀 아키텍처를 검색하고 유효성 검사 성능을 기반으로 최상의 셀을 결정합니다. 두 번째 단계에서는 이러한 셀을 사용하여 더 큰 아키텍처를 구성하고 처음부터 훈련하고 테스트 세트에서 성능을 보고합니다. 또한 ImageNet 및 WikiText-2(WT2)에서 각각 평가하여 CIFAR-10 및 PTB에서 학습된 최상의 셀의 이전 가능성을 조사합니다.

3.1 ARCHITECTURE SEARCH
3.1 아키텍처 검색
3.1.1 SEARCHING FOR CONVOLUTIONAL CELLS ON CIFAR-10
3.1.1 CIFAR-10에서 컨볼루션 셀 검색

O에는 3 × 3 및 5 × 5 분리 가능한 컨볼루션, 3 × 3 및 5 × 5 확장된 분리 가능한 콘볼루션, 3 × 3 최대 풀링, 3 × 3 평균 풀링, 항등 및 0이 포함됩니다. 모든 작업은 스트라이드 1(해당되는 경우)이며 컨볼루션된 피쳐 맵은 공간 해상도를 유지하기 위해 채워집니다. 우리는 ReLU-Conv-BN 순서를 convolutional 연산에 사용하며, 분리 가능한 각 convolution은 항상 두 번 적용됩니다(Zoph et al., 2018; Real et al., 2018; Liu et al., 2018a).

우리의 컨볼루션 셀은 N = 7개의 노드로 구성되며, 그 중 출력 노드는 모든 중간 노드의 깊이 방향 연결로 정의됩니다(입력 노드 제외). 나머지 설정은 Zoph et al.을 따릅니다. (2018); Liu et al. (2018a); Real et al. (2018), 여기에서 네트워크는 여러 셀을 함께 쌓아서 형성됩니다. 셀 k의 첫 번째 및 두 번째 노드는 각각 셀 k-2 및 셀 k-1의 출력과 동일하게 설정되고 필요에 따라 1x1 컨볼루션이 삽입됩니다. 네트워크 전체 깊이의 1/3과 2/3에 위치한 셀은 입력 노드에 인접한 모든 연산이 보폭 2인 축소 셀입니다. 따라서 아키텍처 인코딩은 (αnormal, αreduce)이며, 여기서 αnormal은 모든 정상 셀에서 공유되고 αreduce는 모든 축소 셀에서 공유됩니다. 이 섹션에 대한 자세한 실험 설정은 섹션에서 찾을 수 있습니다. A.1.1.

3.1.2 SEARCHING FOR RECURRENT CELLS ON PENN TREEBANK
3.1.2 Penn TREEBANK에서 반복 세포 검색

사용 가능한 연산 세트에는 tanh, relu, sigmoid 활성화 중 하나가 뒤따르는 선형 변환과 ID 매핑 및 0 연산이 포함됩니다. 이러한 후보 작업의 선택은 Zoph & Le(2017)를 따릅니다. Pham et al. (2018b).

순환 셀은 N = 12개의 노드로 구성됩니다. 가장 첫 번째 중간 노드는 두 개의 입력 노드를 선형으로 변환하고 결과를 더한 다음 ENAS 셀에서 수행된 것처럼 tanh 활성화 함수를 통과하여 얻습니다(Pham et al., 2018b). 나머지 세포는 학습됩니다. 다른 설정은 ENAS와 유사하며, 각 작업은 고속도로 우회로 향상되고(Zilly et al., 2016) 셀 출력은 모든 중간 노드의 평균으로 정의됩니다. ENAS에서와 같이 각 노드에서 배치 정규화를 활성화하여 아키텍처 검색 중에 기울기 폭발을 방지하고 아키텍처 평가 중에 비활성화합니다. 우리의 순환 네트워크는 단일 셀로만 구성됩니다. 즉, 순환 아키텍처 내에서 반복적인 패턴을 가정하지 않습니다. 그림3
이 섹션에 대한 자세한 실험 설정은 섹션에서 찾을 수 있습니다. A.1.2.
그림 4, 5, 6

3.2 아키텍처 평가

최종 평가를 위한 아키텍처를 결정하기 위해 DARTS를 다른 임의 시드로 4번 실행하고 짧은 기간(CIFAR-10에서 100 epoch 및 PTB에서 300 epoch) 처음부터 학습하여 얻은 검증 성능을 기반으로 최상의 셀을 선택합니다. 최적화 결과가 초기화에 민감할 수 있으므로 이는 순환 세포에 특히 중요합니다(그림 3).

선택한 아키텍처를 평가하기 위해 가중치를 무작위로 초기화하고(검색 프로세스 중에 학습된 가중치는 폐기됨), 처음부터 학습하고 테스트 세트에서 성능을 보고합니다. 테스트 세트는 아키텍처 검색 또는 아키텍처 선택에 사용되지 않습니다.

CIFAR-10 및 PTB에 대한 아키텍처 평가를 위한 자세한 실험 설정은 섹션에서 찾을 수 있습니다. A.2.1 및 섹션. A.2.2, 각각. CIFAR-10 및 PTB 외에도 ImageNet(모바일 설정) 및 WikiText-2에서 각각 평가하여 최상의 컨볼루션 셀(CIFAR-10에서 검색) 및 순환 셀(PTB에서 검색)의 전송 가능성을 추가로 조사했습니다. 전이 학습 실험에 대한 자세한 내용은 Sect. A.2.3 및 섹션. A.2.4.
표 1, 2, 3

3.3 결과 분석

컨볼루션 아키텍처에 대한 CIFAR-10 결과는 표 1에 나와 있습니다. 특히 DARTS는 100배 적은 계산 리소스를 사용하면서 최신 기술(Zoph et al., 2018; Real et al., 2018)과 비슷한 결과를 얻었습니다. (즉, 1.5 또는 4 GPU 일 대 NASNet의 경우 2000 GPU 일, AmoebaNet의 경우 3150 GPU 일). 또한 검색 시간이 약간 더 길면서 DARTS는 오류율은 비슷하지만 매개변수가 적은 셀을 발견하여 ENAS보다 성능이 뛰어났습니다(Pham et al., 2018b). 검색 시간이 긴 것은 셀 선택을 위해 검색 과정을 4번 반복했기 때문입니다. 그러나 발견된 아키텍처의 성능이 초기화에 크게 의존하지 않기 때문에 이 방식은 컨볼루션 셀에서는 덜 중요합니다(그림 3).

대안 최적화 전략 이중 수준 최적화의 필요성을 더 잘 이해하기 위해 좌표 하강을 사용하여 훈련 및 검증 세트의 합집합에 대해 α 및 w가 공동으로 최적화되는 단순 검색 전략을 조사했습니다. 결과로 나온 최상의 컨볼루션 셀(4개 실행 중)은 3.1M 매개변수를 사용하여 4.16 ± 0.16% 테스트 오류를 ​​생성했으며 이는 임의 검색보다 나쁩니다. 두 번째 실험에서 우리는 사용 가능한 모든 데이터(훈련 + 검증)에 대해 SGD를 사용하여 w(변경 없이)와 동시에 α를 최적화했습니다. 결과로 나온 최상의 셀은 3.0M 매개변수를 사용하여 3.56 ± 0.10% 테스트 오류를 ​​생성했습니다. 우리는 이러한 휴리스틱이 α(초매개변수와 유사)가 훈련 데이터에 과적합되어 일반화되지 않을 것이라고 가정합니다. α는 DARTS의 훈련 세트에서 직접 최적화되지 않습니다.

표 2는 DARTS에서 발견한 셀이 55.7의 테스트 복잡도를 달성한 PTB의 반복 아키텍처에 대한 결과를 보여줍니다. 이것은 소프트맥스(Yang et al., 2018)의 혼합으로 강화된 최신 모델과 동등하며 수동 또는 자동으로 발견되는 나머지 모든 아키텍처보다 우수합니다. 자동 검색된 셀은 광범위하게 조정된 LSTM(Melis et al., 2018)보다 성능이 우수하여 하이퍼파라미터 검색과 함께 아키텍처 검색의 중요성을 보여줍니다. 효율성 측면에서 전체 비용(총 4회 실행)은 1 GPU 일 이내로 ENAS와 비슷하고 NAS보다 훨씬 빠릅니다(Zoph & Le, 2017).

랜덤 검색은 검색 공간 디자인의 중요성을 반영하는 컨볼루션 모델과 순환 모델 모두에서 경쟁력이 있다는 점도 흥미롭습니다. 그럼에도 불구하고, 비슷하거나 더 적은 검색 비용으로 DARTS는 두 경우 모두에서 무작위 검색을 크게 향상시킬 수 있습니다(CIFAR-10에서 2.76 ± 0.09 대 3.29 ± 0.15, PTB에서 55.7 대 59.4).

표 3의 결과는 CIFAR-10에서 학습된 셀이 실제로 ImageNet으로 전송될 수 있음을 보여줍니다. DARTS가 최첨단 RL 방법(Zoph et al., 2018)으로 경쟁력 있는 성능을 달성하면서 계산 리소스를 3배 적게 사용한다는 점은 주목할 가치가 있습니다.

표 4는 전체 결과가 PTB에 대해 표 2에 제시된 것보다 덜 강력하지만 DARTS에 의해 식별된 세포가 ENAS보다 WT2로 더 잘 전달됨을 보여줍니다. CIFAR-10과 ImageNet 간의 전송 가능성과 비교하여 PTB와 WT2 간의 전송 가능성이 약한 것은 아키텍처 검색을 위한 소스 데이터 세트(PTB)의 크기가 상대적으로 작기 때문에 설명할 수 있습니다. 전송 가능성 문제는 관심 있는 작업에서 아키텍처를 직접 최적화하여 잠재적으로 우회할 수 있습니다.
표 4

4 결론

우리는 컨볼루션 네트워크와 순환 네트워크 모두를 위한 간단하면서도 효율적인 아키텍처 검색 알고리즘인 DARTS를 제시했습니다. 연속 공간에서 검색함으로써 DARTS는 이미지 분류 및 언어 모델링 작업에 대한 최첨단 비 미분 아키텍처 검색 방법과 일치하거나 몇 배의 놀라운 효율성 향상으로 성능을 능가할 수 있습니다.

DARTS를 더욱 개선하기 위한 흥미로운 방향이 많이 있습니다. 예를 들어, 현재 방법은 연속 아키텍처 인코딩과 파생된 이산 아키텍처 간의 불일치로 인해 어려움을 겪을 수 있습니다. 이것은 예를 들어 소프트맥스 온도(적절한 일정으로)를 어닐링하여 원-핫 선택을 시행함으로써 완화될 수 있습니다. 검색 프로세스 동안 학습된 공유 매개변수를 기반으로 성능 인식 아키텍처 파생 체계를 조사하는 것도 흥미로울 것입니다.